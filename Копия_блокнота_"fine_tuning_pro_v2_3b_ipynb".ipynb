{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tuning Diffusion Model v2.3b\n",
        "colab実装：kizamimi, tonimono\n",
        "\n",
        "　\n",
        "\n",
        "### このコードで使用したプログラムの参考サイト\n",
        "\n",
        "DiffusersベースでStable Diffusionをfine tuningする（Kohya S.様）2022/12/04\n",
        "\n",
        "https://note.com/kohya_ss/n/nbf7ce8d80f29"
      ],
      "metadata": {
        "id": "elu5I5ChtHM3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "5xi-MABdtBuT",
        "outputId": "4329c36a-2459-42d3-81c7-3fa6ab7e23dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15360 MiB, 15109 MiB\n"
          ]
        }
      ],
      "source": [
        "#@title Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part0 データセットフォルダの作成"
      ],
      "metadata": {
        "id": "ykOFlGpStaSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part0-1 google driveと接続する\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PfrgSl1utWAW",
        "outputId": "232c68bf-6166-476b-edbc-9881c5bd56ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part0-2 新しいデータセットを作成する\n",
        "!mkdir /content/drive/MyDrive/My_Finetuing\n",
        "import os\n",
        "path = \"/content/drive/MyDrive/My_Finetuing\"\n",
        "files = os.listdir(path=path)\n",
        "max_i = 0\n",
        "for f in files:\n",
        "  if os.path.isdir(os.path.join(path, f)):\n",
        "    if(max_i < int(f)):\n",
        "      max_i = int(f)\n",
        "max_i += 1\n",
        "!mkdir /content/drive/MyDrive/My_Finetuing/{max_i}\n",
        "!mkdir /content/drive/MyDrive/My_Finetuing/{max_i}/dataset\n",
        "!mkdir /content/drive/MyDrive/My_Finetuing/{max_i}/My_Custom_ckpt\n",
        "print(\"MyDrive/My_Finetuing/\"+str(max_i)+\"/dataset にデータセットを入れてください\")\n",
        "print(\"MyDrive/My_Finetuing/\"+str(max_i)+\"/My_Custom_ckpt にカスタムモデルを入れてください\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hYM6tu86thPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31b89c2-92b5-4b02-9af8-eb8d2cee8ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive/My_Finetuing/1/dataset にデータセットを入れてください\n",
            "MyDrive/My_Finetuing/1/My_Custom_ckpt にカスタムモデルを入れてください\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part1 diffusion modelの追加学習"
      ],
      "metadata": {
        "id": "_UcKeUGCtiuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part1-1 google driveと接続する\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nGtNySI9tlUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part1-2 Part1のどれかを使用するとき毎回実行する初期設定\n",
        "\n",
        "%pip install diffusers[torch]==0.9.0\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers>=4.21.0 ftfy bitsandbytes einops pytorch_lightning tensorflow-io>=0.22.0 fairscale==0.4.4 timm==0.4.12\n",
        "#%pip install https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+1515f77.d20221130-cp38-cp38-linux_x86_64.whl\n",
        "!pip install https://github.com/brian6091/xformers-wheels/releases/download/0.0.15.dev0%2B4c06c79/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl\n",
        "!git clone https://github.com/mili-inch/finetuning_by_kohya_s.git train\n",
        "\n",
        "#@markdown ーーーーーーーーーー訓練済みモデル(ckptのURL)の指定ーーーーーーーーー\n",
        "pretrained_model_tag= \"WD1.3_lite\" #@param [\"WD1.3_lite\", \"WD1.3\", \"SD1.4\", \"SD1.5\", \"trinart_V2_60Ksteps\", \"trinart_V2_95Ksteps\", \"trinart_V2_115Ksteps\", \"derrida\", \"trinart_characters\"] {allow-input: false}\n",
        "#@markdown ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "import os\n",
        "import glob\n",
        "path = \"/content/drive/MyDrive/My_Finetuing\"\n",
        "files = os.listdir(path=path)\n",
        "max_i = 0\n",
        "for f in files:\n",
        "  if os.path.isdir(os.path.join(path, f)):\n",
        "    if(max_i < int(f)):\n",
        "      max_i = int(f)\n",
        "\n",
        "if(pretrained_model_tag == \"custom model\"):\n",
        "  pretrained_model = glob.glob(\"/content/drive/MyDrive/My_Finetuing/\"+str(max_i)+\"/My_Custom_ckpt/*\")[0]\n",
        "elif(pretrained_model_tag == \"WD1.3_lite\"):\n",
        "  pretrained_model = \"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\"\n",
        "elif(pretrained_model_tag == \"WD1.3\"):\n",
        "  pretrained_model = \"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-full.ckpt\"\n",
        "elif(pretrained_model_tag == \"WD1.3_full\"):\n",
        "  pretrained_model = \"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-full-opt.ckpt\"\n",
        "elif(pretrained_model_tag == \"SD1.4\"):\n",
        "  pretrained_model = \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4-full-ema.ckpt\"\n",
        "elif(pretrained_model_tag == \"SD1.5\"):\n",
        "  pretrained_model = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.ckpt\"\n",
        "elif(pretrained_model_tag == \"trinart_V2_115Ksteps\"):\n",
        "  pretrained_model = \"https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step115000.ckpt\"\n",
        "elif(pretrained_model_tag == \"trinart_V2_95Ksteps\"):\n",
        "  pretrained_model = \"https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step95000.ckpt\"\n",
        "elif(pretrained_model_tag == \"trinart_V2_60Ksteps\"):\n",
        "  pretrained_model = \"https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step60000.ckpt\"\n",
        "elif(pretrained_model_tag == \"derrida\"):\n",
        "  pretrained_model = \"https://huggingface.co/naclbit/trinart_derrida_characters_v2_stable_diffusion/resolve/main/derrida_final.ckpt\"\n",
        "elif(pretrained_model_tag == \"trinart_characters\"):\n",
        "  pretrained_model = \"https://huggingface.co/naclbit/trinart_characters_19.2m_stable_diffusion_v1/resolve/main/trinart_characters_it4_v1.ckpt\"\n",
        "\n",
        "#@markdown ーーーーーーーーーーーーーーー訓練ステップ数ーーーーーーーーーーーー\n",
        "max_train_steps = 1 #@param {type : \"number\"}\n",
        "#@markdown ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#@markdown ーーーーーーーーーーーーーーーバッチサイズーーーーーーーーーーーーー\n",
        "batch_size = 4 #@param {type : \"number\"}\n",
        "#@markdown ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#@markdown ーーーーーーーーーーーーーーーー学習係数ーーーーーーーーーーーーーー\n",
        "learning_rate = 5e-6 #@param {type : \"number\"}\n",
        "#@markdown ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー"
      ],
      "metadata": {
        "id": "1-B0pS1Mtn6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part1-3 データセットの作成処理\n",
        "#a@markdown データセットのフォルダの中に追加したいプロンプトの名を持つフォルダを\n",
        "\n",
        "import os\n",
        "import glob\n",
        "path = \"/content/drive/MyDrive/My_Finetuing\"\n",
        "root_path = os.path.join(path,str(max_i))\n",
        "dataset_path = os.path.join(path,str(max_i),\"dataset\")\n",
        "files = os.listdir(path=path)\n",
        "max_i = 0\n",
        "for f in files:\n",
        "  if os.path.isdir(os.path.join(path, f)):\n",
        "    if(max_i < int(f)):\n",
        "      max_i = int(f)\n",
        "\n",
        "image_list = sorted(glob.glob(os.path.join(dataset_path,\"*\")))\n",
        "for image in image_list:\n",
        "  print(image)\n",
        "  if(image[-3:] == \"txt\" or image[-3:] == \"npz\"):\n",
        "      os.remove(image)\n",
        "\n",
        "#a@markdown 書いて画像を入れるとその画像用ののプロンプト(タグ)に追加される\n",
        "!git clone https://github.com/KichangKim/DeepDanbooru.git\n",
        "!git -C \"./DeepDanbooru\" checkout c48689a85dde0e4a852c1691a7d746abe242e283\n",
        "!wget https://github.com/KichangKim/DeepDanbooru/releases/download/v3-20211112-sgd-e28/deepdanbooru-v3-20211112-sgd-e28.zip\n",
        "import os\n",
        "import shutil\n",
        "if(os.path.isdir(\"./deepdanbooru-model\")):\n",
        "  shutil.rmtree(\"./deepdanbooru-model\")\n",
        "!unzip \"deepdanbooru-v3-20211112-sgd-e28.zip\" -d \"./deepdanbooru-model\"\n",
        "%pip install ./DeepDanbooru\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "dir = os.listdir(path=os.path.join(dataset_path))\n",
        "\n",
        "image_list = sorted(glob.glob(os.path.join(dataset_path,\"*\")))\n",
        "for image in image_list:\n",
        "  print(image)\n",
        "  if(image[-3:] == \"jpg\"):\n",
        "      im = Image.open(image)\n",
        "      im.save(image[:-3]+'png')\n",
        "      os.remove(image)\n",
        "  if(image[-4:] == \"jpeg\" or image[-4:] == \"jfif\" or image[-4:] == \"webp\"):\n",
        "      im = Image.open(image)\n",
        "      im.save(image[:-4]+'png')\n",
        "      os.remove(image)\n",
        "  if(image[-3:] == \"gif\"):\n",
        "      os.remove(image)\n",
        "\n",
        "##@markdown ーーーーーーーーーーーーー追加するプロンプトーーーーーーーーーーーー\n",
        "#add_prompt = \"\" #@param {type : \"string\"}\n",
        "##@markdown ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "def make_tags(path, fil, tag, id):\n",
        "  files = os.listdir(path)\n",
        "  for f in files:\n",
        "      path_add = os.path.join(path, f)\n",
        "      if os.path.isfile(path_add):\n",
        "          dic = {}\n",
        "          # ファイルの場合\n",
        "          dic[\"base_path\"] = path_add\n",
        "          dic[\"rename_path\"] = os.path.join(path, tag+\"_\"+str(id).zfill(10)+\".png\")\n",
        "          id += 1\n",
        "          json.dump(dic, fil, ensure_ascii=False)\n",
        "          fil.write('\\n')\n",
        "  for f in files:\n",
        "      path_add = os.path.join(path, f)\n",
        "      if os.path.isdir(path_add):\n",
        "          #フォルダの場合\n",
        "          new_tag = \"_\"+f\n",
        "          id = make_tags(path_add, fil, tag + new_tag, id)\n",
        "  return id\n",
        "\n",
        "with open(root_path+\"/dataset_add_tag.jsonl\",\"w\",encoding='utf-8') as fil:\n",
        "  make_tags(dataset_path, fil, \"\", 0)\n",
        "\n",
        "#TODO　ファイル構成をルートに戻す\n",
        "with open(root_path+\"/dataset_add_tag.jsonl\",\"r\",encoding='utf-8') as fil:\n",
        "  for dic in fil:\n",
        "    json_dict = json.loads(dic)\n",
        "    os.rename(json_dict[\"base_path\"],json_dict[\"rename_path\"])\n",
        "    if(\"/\".join(json_dict[\"rename_path\"].split(\"/\")[:-1]) != os.path.join(dataset_path)):\n",
        "      shutil.move(json_dict[\"rename_path\"], os.path.join(dataset_path))\n",
        "\n",
        "!deepdanbooru evaluate {dataset_path} --project-path deepdanbooru-model --allow-folder --save-txt --allow-gpu\n",
        "\n",
        "#dataset_add_tag.txtに基づいてプロンプト情報の変更を加える\n",
        "\n",
        "txt = sorted(glob.glob(os.path.join(dataset_path,\"*.txt\")))\n",
        "for one in txt:\n",
        "  prompt = \"\"\n",
        "  with open(one,\"r\") as f:\n",
        "    prompt = f.readline()\n",
        "  script_prompt = \"_\".join(one.split(\"/\")[-1].split(\"_\"))\n",
        "  print(\"script_prompt:\"+str(script_prompt))\n",
        "  #TODO:script_promptに基づいてプロンプトの状態を決める\n",
        "  sp_prompt = prompt.split(\",\")\n",
        "  if(len(sp_prompt) >= 4):\n",
        "    prompt = \",\".join([sp_prompt[0]]+[sp_prompt[-2]]+sp_prompt[1:-2]+[sp_prompt[-1]])\n",
        "  if(script_prompt.split(\"_\")[1] == \"all\"):\n",
        "    prompt = script_prompt.split(\"_\")[2]\n",
        "  elif(script_prompt.split(\"_\")[1] == \"add\"):\n",
        "    max_i = max(0, int(script_prompt.split(\"_\")[2]))\n",
        "    min_i = min(max_i, len(prompt.split(\",\")))\n",
        "    sp_prompt = prompt.split(\",\")\n",
        "    new_prompt = script_prompt.split(\"_\")[3]\n",
        "    sp_prompt.insert(min_i, new_prompt)\n",
        "    prompt = \",\".join(sp_prompt)\n",
        "  #prompt = add_prompt + \", \" + prompt\n",
        "  with open(one,\"w\") as f:\n",
        "    f.write(prompt)"
      ],
      "metadata": {
        "id": "zpxvFm6Jtwy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part1-4 diffusion modelの追加学習\n",
        "\n",
        "import os\n",
        "path = \"/content/drive/MyDrive/My_Finetuing\"\n",
        "dataset_path = os.path.join(path,str(max_i),\"dataset\")\n",
        "result_path = os.path.join(path,str(max_i),\"result\")\n",
        "\n",
        "!python ./train/merge_dd_tags_to_metadata.py {dataset_path} meta_cap_dd.json\n",
        "!python ./train/clean_captions_and_tags.py {dataset_path} meta_cap_dd.json meta_clean.json\n",
        "!wget {pretrained_model}\n",
        "import os\n",
        "try:\n",
        "  os.rename(pretrained_model.split(\"/\")[-1], 'base.ckpt')\n",
        "except:\n",
        "  pass\n",
        "#--output_dir=./drive/MyDrive/{base_dir}/{result_dir}\n",
        "!python ./train/prepare_buckets_latents.py {dataset_path} meta_clean.json meta_lat.json ./base.ckpt --batch_size 1 --max_resolution 512,512 --mixed_precision no\n",
        "!accelerate launch --config_file=./train/default_config.yaml --num_cpu_threads_per_process 8 ./train/fine_tune.py \\\n",
        "    --pretrained_model_name_or_path=./base.ckpt \\\n",
        "    --in_json=./meta_lat.json \\\n",
        "    --train_data_dir={dataset_path} \\\n",
        "    --output_dir={result_path} \\\n",
        "    --shuffle_caption \\\n",
        "    --train_batch_size={batch_size} \\\n",
        "    --learning_rate=5e-6 \\\n",
        "    --max_train_steps={max_train_steps} \\\n",
        "    --use_8bit_adam \\\n",
        "    --xformers \\\n",
        "    --gradient_checkpointing \\\n",
        "    --mixed_precision=fp16"
      ],
      "metadata": {
        "id": "3eSV0G4Rt1QX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part2 ckpt形式のモデルをdiffusersに変換"
      ],
      "metadata": {
        "id": "O0Vy3kCDt5Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part2-1 google driveと接続する\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sn6ehzabt6co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part2-2 ckpt to diffusers\n",
        "#@markdown Part2-1の実行手順\n",
        "\n",
        "#@markdown １：一回目実行\n",
        "\n",
        "#@markdown ２：Restart Runtimeボタンが実行画面に表示されるのですぐにクリックしてください\n",
        "\n",
        "#@markdown ３：２でのボタンクリックで自動的に再起動\n",
        "\n",
        "#@markdown ４：二回目実行\n",
        "\n",
        "import os\n",
        "path = \"/content/drive/MyDrive/My_Finetuing\"\n",
        "files = os.listdir(path=path)\n",
        "max_i = 0\n",
        "for f in files:\n",
        "  if os.path.isdir(os.path.join(path, f)):\n",
        "    if(max_i < int(f)):\n",
        "      max_i = int(f)\n",
        "dataset_path = os.path.join(path,str(max_i),\"result\",\"last.ckpt\")\n",
        "diff_path = os.path.join(path,str(max_i),\"diffusers_model\")\n",
        "\n",
        "%cd /content\n",
        "!pip install OmegaConf\n",
        "%pip install --upgrade diffusers\n",
        "%pip install -q transformers>=4.21.0\n",
        "!pip install textfile\n",
        "import textfile\n",
        "!wget https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "!git clone https://github.com/huggingface/diffusers\n",
        "!mv v1-inference.yaml ./diffusers/scripts/\n",
        "%cd ./diffusers/scripts\n",
        "path = \"./convert_original_stable_diffusion_to_diffusers.py\"\n",
        "base = \"HeunDiscreteScheduler,\"\n",
        "result = \"\"\n",
        "textfile.replace(path,base,result)\n",
        "base2 = \"from diffusers.pipelines.paint_by_example import PaintByExampleImageEncoder, PaintByExamplePipeline\"\n",
        "result2 = \"#from diffusers.pipelines.paint_by_example import PaintByExampleImageEncoder, PaintByExamplePipeline\"\n",
        "textfile.replace(path,base2,result2)\n",
        "!python ./convert_original_stable_diffusion_to_diffusers.py --checkpoint_path {dataset_path} --dump_path {diff_path}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CHdvzT2wt9p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part3 追加学習したモデルで画像生成"
      ],
      "metadata": {
        "id": "8lQkYLDIuF_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part3-1 google driveと接続する\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0b94vx8BuG5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part3-2 訓練済みモデルのロード\n",
        "#@markdown Part3-2の実行手順\n",
        "\n",
        "%cd /content\n",
        "\n",
        "import os\n",
        "path = \"/content/drive/MyDrive/My_Finetuing\"\n",
        "files = os.listdir(path=path)\n",
        "max_i = 0\n",
        "for f in files:\n",
        "  if os.path.isdir(os.path.join(path, f)):\n",
        "    if(max_i < int(f)):\n",
        "      max_i = int(f)\n",
        "diff_path = os.path.join(path,str(max_i),\"diffusers_model\")\n",
        "\n",
        "#@markdown １：実行\n",
        "\n",
        "#@markdown ２：Part3-3に進む\n",
        "!pip install --upgrade diffusers transformers scipy \n",
        "!pip install accelerate ftfy\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(diff_path, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "i = 0"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZgTPvtNpuKdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part3-3 訓練済みモデルで生成\n",
        "#@markdown Part3-3の実行手順\n",
        "\n",
        "#@markdown １：画像生成に使用するプロンプトと設定を指定してください\n",
        "\n",
        "#@markdown ーーーーーーーーーーーーーーープロンプトーーーーーーーーーーーーーー\n",
        "prompt = \"1girl\" #@param{type:\"string\"}\n",
        "negative_prompt = \"\" #@param{type:\"string\"}\n",
        "#@markdown ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#@markdown ーーーーーーーーー任意の番号（ファイル名に使用します）ーーーーーーー\n",
        "id = 1 #@param{type:\"number\"}\n",
        "#@markdown ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#@markdown ーーーーーーーーーーーーーーーランダムシードーーーーーーーーーーーー\n",
        "seed = -1 #@param{type:\"number\"}\n",
        "#@markdown ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#@markdown ２：実行\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "exe_name = str(id).zfill(3) + \"_result_\"\n",
        "\n",
        "def torch_fix_seed(seed=42):\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True\n",
        "\n",
        "if(seed >= 0):\n",
        "  torch_fix_seed(seed=seed)\n",
        "\n",
        "\n",
        "from IPython.display import Image,display_png\n",
        "\n",
        "for j in range(5):\n",
        "  if(prompt == \"\"):\n",
        "    prompt = f.readline()\n",
        "    f.close()\n",
        "  pipe.enable_attention_slicing()\n",
        "  image = pipe(prompt,negative_prompt=negative_prompt).images[0]  \n",
        "  image.save(exe_name+\"_\"+str(i).zfill(4)+\".png\")\n",
        "  display_png(Image(exe_name+\"_\"+str(i).zfill(4)+\".png\"))\n",
        "  from google.colab import files\n",
        "  files.download(exe_name+\"_\"+str(i).zfill(4)+\".png\")\n",
        "  i+=1"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JxdUBiCLuOkK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}